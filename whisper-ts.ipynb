{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from faster_whisper import WhisperModel\n",
    "\n",
    "from srtranslator import SrtFile\n",
    "from srtranslator.translators.deepl_api import DeeplApi\n",
    "from srtranslator.translators.deepl_scrap import DeeplTranslator\n",
    "from srtranslator.translators.translatepy import TranslatePy\n",
    "\n",
    "import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기본 함수 및 경로 처리\n",
    "\n",
    "def save_to_srt(segments, filename):\n",
    "    with open(filename, 'w', encoding='utf-8') as file:\n",
    "        for index, segment in enumerate(segments, start=1):\n",
    "            start_time = format_time(segment.start)\n",
    "            end_time = format_time(segment.end)\n",
    "            file.write(f\"{index}\\n{start_time} --> {end_time}\\n{segment.text}\\n\\n\")\n",
    "\n",
    "def format_time(seconds):\n",
    "    hours, remainder = divmod(seconds, 3600)\n",
    "    minutes, seconds = divmod(remainder, 60)\n",
    "    milliseconds = int((seconds - int(seconds)) * 1000)\n",
    "    return f\"{int(hours):02d}:{int(minutes):02d}:{int(seconds):02d},{milliseconds:03d}\"\n",
    "\n",
    "# 동영상 파일 경로\n",
    "video_file_path = \"/Users/FELAB/Desktop/yt-dlp/bin/강의1.webm\"\n",
    "\n",
    "# 동영상 파일 이름 가져오기\n",
    "video_filename = os.path.splitext(os.path.basename(video_file_path))[0]\n",
    "\n",
    "# SRT 파일 이름 구성\n",
    "srt_filename = f'{video_filename}.srt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 영어 자막 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run on GPU with FP16\n",
    "model = WhisperModel(model_size_or_path='/Users/FELAB/Desktop/yt-dlp/whipser', device=\"cuda\", compute_type=\"float16\")\n",
    "segments, info = model.transcribe(video_file_path, beam_size=5)\n",
    "print(\"Detected language '%s' with probability %f\" % (info.language, info.language_probability))\n",
    "\n",
    "# Save segments to an SRT file\n",
    "save_to_srt(segments, srt_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 영어 자막을 한글 자막으로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from collections import namedtuple\n",
    "import openai\n",
    "import logging\n",
    "import concurrent.futures\n",
    "\n",
    "logging.basicConfig(filename='translation.log', level=logging.DEBUG, \n",
    "                    format='%(asctime)s %(levelname)s: %(message)s', datefmt='%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "# Ensure you replace 'your-api-key' with the actual OpenAI API key\n",
    "openai.api_key = os.environ[\"OPENAI_API_KEY\"]\n",
    "\n",
    "Subtitle = namedtuple('Subtitle', ['index', 'start', 'end', 'text'])\n",
    "\n",
    "# Function to read the SRT file\n",
    "def read_srt(filename):\n",
    "    with open(filename, 'r', encoding='utf-8') as file:\n",
    "        content = file.read()\n",
    "\n",
    "    subtitles = []\n",
    "    blocks = re.split(r'\\n\\n', content)\n",
    "    for block in blocks:\n",
    "        lines = block.strip().split('\\n')\n",
    "        if len(lines) >= 3:\n",
    "            index = int(lines[0].strip())\n",
    "            start, end = map(str.strip, lines[1].split('-->'))\n",
    "            text = ' '.join(lines[2:])\n",
    "            subtitles.append(Subtitle(index, start, end, text))\n",
    "\n",
    "    return subtitles\n",
    "\n",
    "# Combining subtitles into paragraphs to reduce the number of API calls\n",
    "def combine_subtitles(subtitles, max_length):\n",
    "    paragraphs = []\n",
    "    paragraph = \"\"\n",
    "    times = []\n",
    "\n",
    "    for subtitle in subtitles:\n",
    "        if len(paragraph) + len(subtitle.text) < max_length:\n",
    "            if paragraph:  # if the paragraph is not empty, add a space before appending the next text\n",
    "                paragraph += \" \"\n",
    "            paragraph += subtitle.text\n",
    "            times.append((subtitle.start, subtitle.end))\n",
    "        else:\n",
    "            paragraphs.append((paragraph.strip(), times))\n",
    "            paragraph = subtitle.text\n",
    "            times = [(subtitle.start, subtitle.end)]\n",
    "\n",
    "    if paragraph.strip():  # Adding the last remaining paragraph if it's not empty\n",
    "        paragraphs.append((paragraph.strip(), times))\n",
    "\n",
    "    return paragraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribute translated texts back to timestamps and save to a new SRT file\n",
    "def distribute_and_save_translations(translated_paragraphs, filename):\n",
    "    try:\n",
    "        with open(filename, 'w', encoding='utf-8') as file:\n",
    "            index = 1\n",
    "            for translated_text, times in translated_paragraphs:\n",
    "                if translated_text is None:\n",
    "                    logging.warning(\"Received None as translated text. Skipping...\")\n",
    "                    continue\n",
    "\n",
    "                sentences = translated_text.split('. ')\n",
    "                logging.debug(f\"Translated sentences: {sentences}\")\n",
    "                logging.debug(f\"Timestamps: {times}\")\n",
    "\n",
    "                if len(sentences) != len(times):\n",
    "                    logging.warning(f\"Warning: Mismatch in number of sentences and timestamps for paragraph '{translated_text}'\")\n",
    "                    \n",
    "                    # Implementing a flexible mechanism to associate timestamps with sentences\n",
    "                    avg_duration = len(times) // len(sentences)\n",
    "                    times = [times[i:i + avg_duration] for i in range(0, len(times), avg_duration)]\n",
    "\n",
    "                for i, sentence in enumerate(sentences):\n",
    "                    start = times[i][0][0]\n",
    "                    end = times[i][-1][1]\n",
    "                    file.write(f\"{index}\\n\")\n",
    "                    file.write(f\"{start} --> {end}\\n\")\n",
    "                    file.write(f\"{sentence.strip()}.\\n\\n\")\n",
    "                    index += 1\n",
    "    except Exception as e:\n",
    "        logging.error(f\"An error occurred while saving the file: {e}\")\n",
    "\n",
    "# Existing translation function\n",
    "def translate_text(text):\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You are a helpful translator. Translate the following English text to Korean.\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": text\n",
    "            }\n",
    "        ],\n",
    "        temperature=0.3,\n",
    "        max_tokens=512\n",
    "    )\n",
    "    try:\n",
    "        translated_text = response['choices'][0]['message']['content'].strip()\n",
    "        return translated_text if translated_text else None\n",
    "    except Exception as e:\n",
    "        print(f\"Error in translation: {e}\")\n",
    "        return None\n",
    "\n",
    "def translate_paragraphs_concurrently(paragraphs, max_workers=5):\n",
    "    translated_paragraphs = []\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        future_to_paragraph = {executor.submit(translate_text, paragraph): (paragraph, times) for paragraph, times in paragraphs}\n",
    "        for future in concurrent.futures.as_completed(future_to_paragraph):\n",
    "            paragraph, times = future_to_paragraph[future]\n",
    "            try:\n",
    "                translated_text = future.result()\n",
    "            except Exception as exc:\n",
    "                logging.error(f\"Error in translating paragraph {paragraph[:50]}...: {exc}\")\n",
    "            else:\n",
    "                translated_paragraphs.append((translated_text, times))\n",
    "    return translated_paragraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing the entire process\n",
    "if __name__ == \"__main__\":\n",
    "    subtitles = read_srt('./강의1.srt')  # Replace with the actual path of your SRT file\n",
    "    paragraphs = combine_subtitles(subtitles, 500)  # 500 is a placeholder; adjust the max_length as needed\n",
    "    translated_paragraphs = translate_paragraphs_concurrently(paragraphs, max_workers=32)\n",
    "    distribute_and_save_translations(translated_paragraphs, 'translated.srt')  # Replace with the desired output file name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
